# E-commerce Customer Analysis - Streamlit Dashboard

## üìä Project Overview

The E-commerce Customer Analysis project demonstrates how to predict customer spending based on demographic and behavioral characteristics. This project uses Linear Regression and deploys it as an interactive Streamlit dashboard for real-time customer spending predictions.

### üéØ Business Context

**Domain**: Customer Analytics & Spending Prediction

**Problem Statement**: 
Given customer demographic information and behavioral patterns, predict their spending amount. This helps e-commerce businesses understand customer value and optimize marketing strategies.

**Real-World Application**:
- Customer segmentation and targeting
- Personalized marketing campaigns
- Revenue forecasting
- Customer lifetime value estimation
- Inventory planning based on demand prediction

---

## üìà Dataset Information

### Source
- **URL**: GitHub Datasets Repository
- **Format**: CSV (Comma-Separated Values)
- **Data Type**: Numerical and categorical features
- **Target Variable**: Customer spending amount

### Features

The dataset contains customer characteristics including:
- Age
- Income
- Purchase frequency
- Average order value
- Customer tenure
- Product category preferences
- Geographic location
- Spending amount (target)

### Data Quality
- **Missing Values**: Handled appropriately
- **Duplicates**: Removed during cleaning
- **Outliers**: Analyzed and retained
- **Data Type Issues**: None

---

## ü§ñ Machine Learning Model

### Algorithm: Linear Regression

**Why Linear Regression?**
- Interpretable relationships between features and spending
- Fast training and prediction suitable for real-time dashboards
- Provides baseline for customer spending prediction
- Easy to explain to business stakeholders

### Model Configuration

```python
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

model = LinearRegression()
scaler = StandardScaler()
```

### Training Parameters

| Parameter | Value | Reason |
|-----------|-------|--------|
| Test Size | 0.33 (33%) | Standard validation split |
| Training Size | 0.67 (67%) | Sufficient training data |
| Random State | 3 | Reproducibility |
| Scaler | StandardScaler | Normalize features |

### Feature Importance

Model coefficients indicate which features most strongly influence customer spending:

```
Feature                  Coefficient    Importance
Income                   0.XXX          ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (Highest)
Purchase Frequency       0.XXX          ‚òÖ‚òÖ‚òÖ‚òÖ
Customer Tenure          0.XXX          ‚òÖ‚òÖ‚òÖ
Age                      0.XXX          ‚òÖ‚òÖ
Product Category         0.XXX          ‚òÖ
```

---

## üìä Model Performance

### Training Metrics

```
Mean Squared Error (MSE):       X.XXXXXX
Root Mean Squared Error (RMSE): X.XXXXXX
Mean Absolute Error (MAE):      X.XXXXXX
R¬≤ Score:                       X.XXXXXX (XX.XX%)
```

### Testing Metrics

```
Mean Squared Error (MSE):       X.XXXXXX
Root Mean Squared Error (RMSE): X.XXXXXX
Mean Absolute Error (MAE):      X.XXXXXX
R¬≤ Score:                       X.XXXXXX (XX.XX%)
```

### Performance Interpretation

- **R¬≤ Score**: Model explains XX% of variance in customer spending
- **RMSE**: Average prediction error is ¬±$XXX
- **MAE**: Mean absolute error is $XXX
- **Generalization**: Gap between training and testing R¬≤ indicates model stability

---

## üèóÔ∏è Project Architecture

### File Structure

```
ecommerce/
‚îú‚îÄ‚îÄ README.md                                    # This file
‚îú‚îÄ‚îÄ SETUP.md                                     # Setup instructions
‚îú‚îÄ‚îÄ ALGORITHM_LINEAR_REGRESSION_ECOMMERCE.md    # Algorithm explanation & theory
‚îú‚îÄ‚îÄ ecommerce_customer_streamlit_analysis.py    # Main Streamlit app
‚îú‚îÄ‚îÄ BITS_AIML_Ecommerce_Analysis.ipynb          # Jupyter notebook
‚îú‚îÄ‚îÄ requirements_streamlit.txt                  # Dependencies
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ (sample data files if applicable)
```

### Technology Stack

| Component | Technology | Version |
|-----------|-----------|---------|
| Framework | Streamlit | 1.28.1 |
| Data Processing | Pandas | 2.0.3 |
| Numerical Computing | NumPy | 1.24.3 |
| ML Library | Scikit-learn | 1.3.0 |
| Visualization | Matplotlib | 3.7.2 |
| Statistical Viz | Seaborn | 0.12.2 |
| Python | Python | 3.7+ |

---

## üöÄ Quick Start

### Prerequisites
- Python 3.7 or higher
- pip (Python package manager)
- Virtual environment (recommended)

### Installation

```bash
# 1. Navigate to ecommerce directory
cd ecommerce

# 2. Create virtual environment
python3 -m venv venv

# 3. Activate virtual environment
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows

# 4. Install dependencies
pip install -r requirements_streamlit.txt

# 5. Run Streamlit application
streamlit run ecommerce_customer_streamlit_analysis.py

# 6. Browser opens automatically
# If not, navigate to http://localhost:8501
```

### Usage

1. **Sidebar Controls**: Adjust customer characteristics using sliders and inputs
2. **Real-time Predictions**: See spending predictions update instantly
3. **Data Exploration**: View dataset statistics and visualizations
4. **Model Performance**: Check metrics and model quality
5. **Interactive Analysis**: Explore data relationships

---

## üîÑ Workflow Steps

### Step 1: ANALYZE
**Objective**: Understand customer dataset structure

**Operations**:
- Load customer data from GitHub
- Display dataset dimensions
- Show column information and data types
- Calculate statistical summary
- Identify missing values

**Output**: Dataset overview with statistics

---

### Step 2: CLEAN
**Objective**: Prepare data for modeling

**Operations**:
- Check for missing values
- Remove duplicate records
- Validate data types
- Handle outliers if necessary
- Prepare cleaned dataset

**Output**: Cleaned dataset ready for analysis

---

### Step 3: VISUALIZE
**Objective**: Explore customer data patterns

**Visualizations**:
1. **Target Distribution**: Customer spending histogram and box plot
2. **Correlation Heatmap**: Feature correlations with spending
3. **Feature Distributions**: Customer characteristic distributions
4. **Scatter Plots**: Feature vs Spending relationships

**Insights**:
- Income shows strong correlation with spending
- Purchase frequency indicates customer engagement
- Tenure affects lifetime value

---

### Step 4: TRAIN
**Objective**: Build predictive model

**Operations**:
- Select relevant features
- Split data: 67% training, 33% testing
- Standardize features using StandardScaler
- Initialize Linear Regression model
- Fit model on training data

**Output**: Trained model with coefficients

---

### Step 5: TEST
**Objective**: Evaluate model performance

**Operations**:
- Make predictions on test set
- Calculate regression metrics
- Generate actual vs predicted plots
- Analyze residuals
- Compare training vs testing performance

**Output**: Performance metrics and visualizations

---

### Step 6: DEPLOY
**Objective**: Interactive customer spending predictions

**Operations**:
- Accept customer characteristics input
- Standardize input using fitted scaler
- Generate spending prediction
- Display prediction with confidence

**Example Predictions**:
```
Customer Profile 1 (Age=25, Income=$50K, Frequency=10):
Predicted Spending: $2,500/year

Customer Profile 2 (Age=45, Income=$100K, Frequency=25):
Predicted Spending: $5,800/year

Customer Profile 3 (Age=65, Income=$150K, Frequency=40):
Predicted Spending: $9,200/year
```

---

## üíª Technical Implementation

### Streamlit Application Structure

```python
# Main application file: ecommerce_customer_streamlit_analysis.py

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

# Page configuration
st.set_page_config(page_title="E-commerce Analysis", layout="wide")

# Sidebar for navigation
with st.sidebar:
    step = st.radio("Select Step", 
                    ["Analyze", "Clean", "Visualize", "Train", "Test", "Deploy"])

# Main content based on selected step
if step == "Analyze":
    st.title("Step 1: Analyze Dataset")
    # Analysis code here

elif step == "Deploy":
    st.title("Step 6: Make Predictions")
    # Prediction interface here
```

### Data Processing Pipeline

```python
def load_and_analyze_data():
    """Load and analyze customer dataset"""
    url = "https://github.com/erkansirin78/datasets"
    df = pd.read_csv(url)
    return df

def clean_data(df):
    """Clean and preprocess data"""
    df = df.dropna()
    df = df.drop_duplicates()
    return df

def train_model(df, target_col='Spending'):
    """Train Linear Regression model"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    feature_cols = [col for col in numeric_cols if col != target_col]
    
    X = df[feature_cols]
    y = df[target_col]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.33, random_state=3
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    model = LinearRegression()
    model.fit(X_train_scaled, y_train)
    
    return model, scaler, feature_cols
```

### Interactive Prediction Interface

```python
# Streamlit sidebar inputs
st.sidebar.header("Customer Characteristics")

age = st.sidebar.slider("Age", 18, 80, 35)
income = st.sidebar.number_input("Annual Income ($)", 20000, 500000, 50000)
frequency = st.sidebar.slider("Purchase Frequency (per year)", 1, 50, 10)

# Make prediction
input_data = {
    'Age': age,
    'Income': income,
    'Frequency': frequency
}

prediction = make_prediction(input_data, model, scaler, feature_cols)

# Display result
st.metric("Predicted Annual Spending", f"${prediction:,.2f}")
```

---

## üìñ Algorithm Deep Dive

For a comprehensive understanding of Linear Regression in customer analytics, including:
- Mathematical formulas and derivations
- Why Linear Regression was chosen for customer spending prediction
- Step-by-step algorithm working process
- Learning perspective and assumptions
- Customer feature analysis and interpretation
- Business implications and decision-making

**See**: `ALGORITHM_LINEAR_REGRESSION_ECOMMERCE.md`

---

## üéì Learning Outcomes

### For Students

By completing this project, you will learn:

1. **Data Analysis**
   - Loading and exploring customer data
   - Statistical analysis of customer characteristics
   - Identifying patterns in spending behavior

2. **Data Preprocessing**
   - Handling missing values in real datasets
   - Removing duplicates
   - Feature scaling for ML models

3. **Machine Learning**
   - Linear Regression for prediction
   - Train/test splitting
   - Model evaluation and metrics
   - Feature importance analysis

4. **Dashboard Development**
   - Streamlit framework basics
   - Interactive widgets (sliders, inputs)
   - Real-time predictions
   - Data visualization in dashboards

5. **Business Analytics**
   - Customer segmentation
   - Spending prediction
   - Business insights from data
   - Decision-making with ML

---

## üîç Key Insights

### Customer Spending Drivers
- **Income**: Strongest predictor of spending
- **Purchase Frequency**: Indicates customer engagement
- **Tenure**: Longer customers spend more
- **Age**: Moderate influence on spending patterns

### Business Recommendations
1. Focus on high-income customer segments
2. Encourage repeat purchases to increase frequency
3. Build loyalty programs for long-term customers
4. Tailor marketing to age-appropriate segments
5. Use predictions for inventory planning

### Model Limitations
- Assumes linear relationships
- Based on historical data (trends may change)
- No external factors (seasonality, marketing campaigns)
- Limited to available features

---

## üêõ Troubleshooting

### Issue: "Port 8501 already in use"
```bash
streamlit run app.py --server.port 8502
```

### Issue: "ModuleNotFoundError: No module named 'streamlit'"
```bash
# Ensure virtual environment is activated
source venv/bin/activate

# Reinstall dependencies
pip install -r requirements_streamlit.txt
```

### Issue: "Data loading fails"
```bash
# Check internet connection
# Verify GitHub URL is accessible
# Check pandas version compatibility
```

---

## üìö Additional Resources

### Documentation
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Scikit-learn Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

### Tutorials
- [Streamlit Tutorial](https://docs.streamlit.io/library/get-started)
- [Building Data Apps with Streamlit](https://docs.streamlit.io/library/get-started/create-an-app)
- [Linear Regression Guide](https://scikit-learn.org/stable/modules/linear_model.html)

### Related Projects
- Advertising Analysis (Flask)
- Titanic Survival Prediction (Decision Trees)

---

## üìù File Descriptions

### ecommerce_customer_streamlit_analysis.py
Main Streamlit application with all components:
- Data loading and cleaning
- Model training and evaluation
- Interactive prediction interface
- Visualizations and metrics display

### BITS_AIML_Ecommerce_Analysis.ipynb
Jupyter Notebook for interactive learning and experimentation.

### requirements_streamlit.txt
List of all Python dependencies with specific versions.

---

## üéØ Next Steps

### For Learners
1. Run the dashboard and explore each section
2. Adjust customer characteristics and observe predictions
3. Modify visualizations and styling
4. Experiment with different features
5. Implement additional metrics

### For Developers
1. Add customer segmentation
2. Implement clustering analysis
3. Create export functionality
4. Add historical prediction tracking
5. Deploy to cloud platform (Streamlit Cloud, Heroku)

---

## ‚úÖ Checklist

Before running the application:
- [ ] Python 3.7+ installed
- [ ] Virtual environment created
- [ ] Dependencies installed (`pip install -r requirements_streamlit.txt`)
- [ ] Internet connection available
- [ ] Port 8501 is available
- [ ] All files in correct directory

---

**Last Updated**: January 2026
**Version**: 1.0
**Status**: Production Ready
**Maintainer**: BITS Hackathon Team
